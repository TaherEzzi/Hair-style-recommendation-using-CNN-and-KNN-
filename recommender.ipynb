{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802b0725-751d-4148-8aad-acb8d0c3b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (2.19.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (3.10.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (10.4.0)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (2.1.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (4.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets)\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (8.32.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: rich in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading faiss_cpu-1.11.0-cp312-cp312-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/15.0 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 5.2/15.0 MB 16.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.0/15.0 MB 20.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 20.5 MB/s eta 0:00:00\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 30.7 MB/s eta 0:00:00\n",
      "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, faiss-cpu, comm, ipywidgets\n",
      "\n",
      "   -------- ------------------------------- 1/5 [jupyterlab_widgets]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   ---------------- ----------------------- 2/5 [faiss-cpu]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   -------------------------------- ------- 4/5 [ipywidgets]\n",
      "   ---------------------------------------- 5/5 [ipywidgets]\n",
      "\n",
      "Successfully installed comm-0.2.2 faiss-cpu-1.11.0 ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n",
      "Block 1: No error\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu opencv-python tensorflow scikit-learn matplotlib pillow ipywidgets\n",
    "\n",
    "print(\"Block 1: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da155e6-0afc-492e-a11d-63af2b243e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 2: No error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Configure for speed\n",
    "tf.config.experimental.enable_memory_growth = True\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(\"Block 2: No error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0144bc44-5e7b-404b-9c57-d9032aa0dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 3: No error\n"
     ]
    }
   ],
   "source": [
    "class FastConfig:\n",
    "    embedding_dim = 128\n",
    "    image_size = (160, 160)\n",
    "    top_k = 6\n",
    "    cache_dir = 'fast_cache'\n",
    "\n",
    "config = FastConfig()\n",
    "\n",
    "print(\"Block 3: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8a92dc-f3d3-4d47-94ae-e40385f81489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Block 4: No error\n"
     ]
    }
   ],
   "source": [
    "class UltraFastExtractor:\n",
    "    def __init__(self):\n",
    "        self.base_model = MobileNetV2(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            pooling='avg',\n",
    "            input_shape=(*config.image_size, 3)\n",
    "        )\n",
    "        \n",
    "        self.model = tf.keras.Sequential([\n",
    "            self.base_model,\n",
    "            tf.keras.layers.Dense(config.embedding_dim, activation='relu'),\n",
    "            tf.keras.layers.Lambda(lambda x: tf.nn.l2_normalize(x, axis=1))\n",
    "        ])\n",
    "        \n",
    "        self.model.compile(optimizer='adam')\n",
    "        dummy_input = np.random.random((1, *config.image_size, 3)).astype(np.float32)\n",
    "        self.model.predict(dummy_input, verbose=0)\n",
    "    \n",
    "    def extract_fast(self, img_array):\n",
    "        if len(img_array.shape) == 3:\n",
    "            img_array = np.expand_dims(img_array, axis=0)\n",
    "        \n",
    "        img_array = preprocess_input(img_array.astype(np.float32))\n",
    "        embedding = self.model.predict(img_array, verbose=0)\n",
    "        return embedding.flatten()\n",
    "\n",
    "extractor = UltraFastExtractor()\n",
    "\n",
    "print(\"Block 4: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b814e667-5688-4bea-a818-0b1bdfcb38a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 5: No error\n"
     ]
    }
   ],
   "source": [
    "class LightningSearch:\n",
    "    def __init__(self):\n",
    "        self.indices = {}\n",
    "        self.paths = {}\n",
    "        self.thumbnails = {}\n",
    "        \n",
    "    def load_precomputed_data(self, gender):\n",
    "        cache_file = f\"{config.cache_dir}/{gender}_fast_cache.npz\"\n",
    "        \n",
    "        if not os.path.exists(cache_file):\n",
    "            print(f\"Cache file not found: {cache_file}\")\n",
    "            return False\n",
    "        \n",
    "        data = np.load(cache_file, allow_pickle=True)\n",
    "        embeddings = data['embeddings']\n",
    "        paths = data['paths']\n",
    "        thumbnails = data['thumbnails']\n",
    "        \n",
    "        index = faiss.IndexFlatIP(config.embedding_dim)\n",
    "        index.add(embeddings.astype('float32'))\n",
    "        \n",
    "        self.indices[gender] = index\n",
    "        self.paths[gender] = paths\n",
    "        self.thumbnails[gender] = thumbnails\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def search_lightning_fast(self, query_embedding, gender, k=6):\n",
    "        if gender not in self.indices:\n",
    "            if not self.load_precomputed_data(gender):\n",
    "                return [], []\n",
    "        \n",
    "        query_norm = query_embedding / np.linalg.norm(query_embedding)\n",
    "        query_norm = query_norm.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        similarities, indices = self.indices[gender].search(query_norm, k)\n",
    "        \n",
    "        result_thumbnails = [self.thumbnails[gender][idx] for idx in indices[0]]\n",
    "        scores = similarities[0]\n",
    "        \n",
    "        return result_thumbnails, scores\n",
    "\n",
    "search_engine = LightningSearch()\n",
    "\n",
    "print(\"Block 5: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a05cc9da-ec5a-4595-990e-6e6fb6e6ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 6: No error\n"
     ]
    }
   ],
   "source": [
    "def capture_face_ultra_fast():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    print(\"Press ENTER to capture, ESC to exit\")\n",
    "    \n",
    "    captured_face = None\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        for (x, y, w, h) in faces:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, 'Face Detected!', (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        cv2.putText(frame, 'ENTER: Capture | ESC: Exit', (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow('Face Capture', frame)\n",
    "        \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == 13:  # Enter\n",
    "            if len(faces) > 0:\n",
    "                x, y, w, h = max(faces, key=lambda f: f[2]*f[3])\n",
    "                face_img = frame[y:y+h, x:x+w]\n",
    "                captured_face = cv2.resize(face_img, config.image_size)\n",
    "                break\n",
    "            else:\n",
    "                print(\"No face detected!\")\n",
    "        elif key == 27:  # Escape\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return captured_face\n",
    "\n",
    "print(\"Block 6: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceaa4978-f9f9-4ee3-9ae9-18f9834237d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 7: No error\n"
     ]
    }
   ],
   "source": [
    "def create_instant_collage(thumbnails, scores):\n",
    "    cols, rows = 3, 2\n",
    "    thumb_size = 200\n",
    "    margin = 20\n",
    "    \n",
    "    collage_width = cols * thumb_size + (cols + 1) * margin\n",
    "    collage_height = rows * thumb_size + (rows + 1) * margin + 60\n",
    "    \n",
    "    collage = Image.new('RGB', (collage_width, collage_height), (40, 40, 40))\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 24)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    draw = ImageDraw.Draw(collage)\n",
    "    title = \"Your Top Matches\"\n",
    "    title_bbox = draw.textbbox((0, 0), title, font=font)\n",
    "    title_width = title_bbox[2] - title_bbox[0]\n",
    "    title_x = (collage_width - title_width) // 2\n",
    "    draw.text((title_x, 10), title, fill=(255, 255, 255), font=font)\n",
    "    \n",
    "    for i, (thumbnail, score) in enumerate(zip(thumbnails, scores)):\n",
    "        if i >= 6:\n",
    "            break\n",
    "            \n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        x = margin + col * (thumb_size + margin)\n",
    "        y = 50 + margin + row * (thumb_size + margin)\n",
    "        \n",
    "        if isinstance(thumbnail, np.ndarray):\n",
    "            if thumbnail.shape[2] == 3:\n",
    "                thumbnail = cv2.cvtColor(thumbnail, cv2.COLOR_BGR2RGB)\n",
    "            pil_thumb = Image.fromarray(thumbnail)\n",
    "        else:\n",
    "            pil_thumb = thumbnail\n",
    "            \n",
    "        pil_thumb = pil_thumb.resize((thumb_size, thumb_size), Image.Resampling.LANCZOS)\n",
    "        collage.paste(pil_thumb, (x, y))\n",
    "        \n",
    "        score_text = f\"{score:.3f}\"\n",
    "        score_bbox = draw.textbbox((0, 0), score_text, font=font)\n",
    "        score_bg = Image.new('RGBA', (score_bbox[2] + 10, score_bbox[3] + 4), (0, 0, 0, 180))\n",
    "        collage.paste(score_bg, (x + 5, y + thumb_size - 25), score_bg)\n",
    "        draw.text((x + 10, y + thumb_size - 23), score_text, fill=(255, 255, 255), font=font)\n",
    "    \n",
    "    return collage\n",
    "\n",
    "print(\"Block 7: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c57b47cd-595f-4eb1-8266-d367af84c316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 8: No error\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataset_for_speed(dataset_dir, gender):\n",
    "    os.makedirs(config.cache_dir, exist_ok=True)\n",
    "    \n",
    "    gender_dir = Path(dataset_dir) / gender / gender\n",
    "    if not gender_dir.exists():\n",
    "        print(f\"Dataset directory not found: {gender_dir}\")\n",
    "        return\n",
    "    \n",
    "    image_paths = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:\n",
    "        image_paths.extend(gender_dir.glob(ext))\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"No images found in {gender_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "    \n",
    "    embeddings = []\n",
    "    thumbnails = []\n",
    "    valid_paths = []\n",
    "    \n",
    "    batch_size = 32\n",
    "    total_processed = 0\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i+batch_size]\n",
    "        batch_images = []\n",
    "        batch_thumbnails = []\n",
    "        batch_valid_paths = []\n",
    "        \n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                img = cv2.imread(str(path))\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                img_resized = cv2.resize(img, config.image_size)\n",
    "                batch_images.append(img_resized)\n",
    "                \n",
    "                thumbnail = cv2.resize(img, (200, 200))\n",
    "                batch_thumbnails.append(thumbnail)\n",
    "                \n",
    "                batch_valid_paths.append(str(path))\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if not batch_images:\n",
    "            continue\n",
    "        \n",
    "        batch_embeddings = []\n",
    "        for img in batch_images:\n",
    "            try:\n",
    "                embedding = extractor.extract_fast(img)\n",
    "                batch_embeddings.append(embedding)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        embeddings.extend(batch_embeddings)\n",
    "        thumbnails.extend(batch_thumbnails)\n",
    "        valid_paths.extend(batch_valid_paths)\n",
    "        \n",
    "        total_processed += len(batch_embeddings)\n",
    "        print(f\"Processed {total_processed}/{len(image_paths)} images\")\n",
    "    \n",
    "    if not embeddings:\n",
    "        print(f\"No valid embeddings extracted for {gender}\")\n",
    "        return\n",
    "    \n",
    "    embeddings = np.array(embeddings)\n",
    "    thumbnails = np.array(thumbnails)\n",
    "    valid_paths = np.array(valid_paths)\n",
    "    \n",
    "    cache_file = f\"{config.cache_dir}/{gender}_fast_cache.npz\"\n",
    "    np.savez_compressed(\n",
    "        cache_file,\n",
    "        embeddings=embeddings,\n",
    "        paths=valid_paths,\n",
    "        thumbnails=thumbnails\n",
    "    )\n",
    "    \n",
    "    print(f\"Preprocessing complete for {gender}\")\n",
    "    print(f\"Cache saved: {cache_file}\")\n",
    "\n",
    "print(\"Block 8: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5fe4f5c-443c-4483-ade4-180efdaaac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block 9: No error\n"
     ]
    }
   ],
   "source": [
    "def get_instant_recommendations():\n",
    "    gender = input(\"Enter gender (male/female): \").strip().lower()\n",
    "    \n",
    "    if gender not in ['male', 'female']:\n",
    "        print(\"Invalid gender! Please enter 'male' or 'female'\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Starting recommendations for {gender}...\")\n",
    "    \n",
    "    face_img = capture_face_ultra_fast()\n",
    "    \n",
    "    if face_img is None:\n",
    "        print(\"No face captured!\")\n",
    "        return\n",
    "    \n",
    "    print(\"Analyzing your face...\")\n",
    "    face_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "    embedding = extractor.extract_fast(face_rgb)\n",
    "    \n",
    "    print(\"Finding matches...\")\n",
    "    thumbnails, scores = search_engine.search_lightning_fast(embedding, gender, k=6)\n",
    "    \n",
    "    if not thumbnails:\n",
    "        print(f\"No matches found for gender: {gender}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Creating collage...\")\n",
    "    collage = create_instant_collage(thumbnails, scores)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(collage)\n",
    "    plt.axis('off')\n",
    "    plt.title('Your Face Recommendations', fontsize=16, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Recommendations complete!\")\n",
    "\n",
    "print(\"Block 9: No error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee7188be-4b95-4964-86d1-07001fe07787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter gender (male/female):  male\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting recommendations for male...\n",
      "Press ENTER to capture, ESC to exit\n",
      "Analyzing your face...\n",
      "Finding matches...\n",
      "Cache file not found: fast_cache/male_fast_cache.npz\n",
      "No matches found for gender: male\n"
     ]
    }
   ],
   "source": [
    "get_instant_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce0e3b-c347-4159-98e3-9a5314a84f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
